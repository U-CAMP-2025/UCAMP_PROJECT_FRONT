import React, { useEffect, useRef, useState } from 'react';
import { useParams } from 'react-router-dom';
import RecordRTC, { RecordRTCPromisesHandler } from 'recordrtc';

import TextToSpeech from './TextToSpeech';

const QUESTIONS = [
  'ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.',
  'ìš°ë¦¬ íšŒì‚¬ì— ì§€ì›í•œ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?',
  'ìµœê·¼ì— í•´ê²°í•œ ì–´ë ¤ìš´ ë¬¸ì œ í•˜ë‚˜ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.',
  'í˜‘ì—…ì—ì„œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ì ì€?',
  'ì…ì‚¬ í›„ 3ë…„ ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?',
];

const voiceId = 'Xb7hH8MSUJpSbSDYk0k2';

const MAX_SECONDS = 60; // ì§ˆë¬¸ë‹¹ ì œí•œ ì‹œê°„(ì´ˆ)

export default function SimulationGO() {
  // param
  const { simulationId } = useParams();
  const [simInfo, setSimInfo] = useState(null);
  const [loading, setLoading] = useState(true);
  // ìƒíƒœ
  const [currentIdx, setCurrentIdx] = useState(0);
  const [currentQuestion, setcurrentQuestion] = useState('');
  const [timeLeft, setTimeLeft] = useState(MAX_SECONDS);
  const [isSessionStarted, setIsSessionStarted] = useState(false);
  const [isQuestionRecording, setIsQuestionRecording] = useState(false);

  // ğŸ”Š TTS refs (âœ… ë°˜ë“œì‹œ ì»´í¬ë„ŒíŠ¸ ë‚´ë¶€ì— ìˆì–´ì•¼ í•¨)
  const synthRef = useRef(null);
  const voiceRef = useRef(null); // ì„ íƒëœ ìŒì„± ìºì‹œ
  const utterRef = useRef(null); // í˜„ì¬ ë°œí™” ê°ì²´

  // ë¯¸ë””ì–´
  const videoElRef = useRef(null);
  const videoStreamRef = useRef(null); // ë¹„ë””ì˜¤(+ë§ˆì´í¬) ìŠ¤íŠ¸ë¦¼ (ì„¸ì…˜ ì „ì²´ ë…¹í™”)
  const audioStreamRef = useRef(null); // ì˜¤ë””ì˜¤ ì „ìš© ìŠ¤íŠ¸ë¦¼ (ì§ˆë¬¸ë³„ ë…¹ìŒ)

  // ë ˆì½”ë”
  const videoRecRef = useRef(null); // ì„¸ì…˜ ì „ì²´ ë¹„ë””ì˜¤ ë ˆì½”ë”
  const audioRecRef = useRef(null); // ì§ˆë¬¸ë³„ ì˜¤ë””ì˜¤ ë ˆì½”ë”

  // ê²°ê³¼
  const [videoUrl, setVideoUrl] = useState(null);
  const [audioUrls, setAudioUrls] = useState([]); // indexë³„ ì˜¤ë””ì˜¤ URL ì €ì¥

  // íƒ€ì´ë¨¸
  const timerRef = useRef(null); // 1ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´ í‘œì‹œìš©
  const timeoutRef = useRef(null); // 60ì´ˆ ë§Œë£Œ ì²˜ë¦¬ìš© (ë‹¨ë°œ)
  const finishingRef = useRef(false); // ì¤‘ë³µ ì™„ë£Œ ë°©ì§€ ê°€ë“œ

  useEffect(() => {
    async function fetchSimulation() {
      try {
        // axiosInstance ì‚¬ìš© ì‹œ:
        // const { data } = await axiosInstance.get(`/simulation/${simulationId}`);
        // setSimInfo(data.data);

        // ë§Œì•½ ì•„ì§ APIê°€ ì—†ë‹¤ë©´ ì•„ë˜ ë‘ ì¤„ë§Œ ë‘ê³  ë„˜ì–´ê°€ë„ ë©ë‹ˆë‹¤.
        setSimInfo({ id: simulationId });
      } catch (e) {
        console.error(e);
      } finally {
        setLoading(false);
      }
    }
    if (simulationId) fetchSimulation();
  }, [simulationId]);

  // ğŸ”Š TTS ì´ˆê¸°í™”
  useEffect(() => {
    if (typeof window === 'undefined' || !('speechSynthesis' in window)) return;
    synthRef.current = window.speechSynthesis;

    const pickVoice = () => {
      const list = synthRef.current.getVoices();
      // 1) Google í•œêµ­ â†’ 2) ko-* â†’ 3) ì²« ë²ˆì§¸
      const googleKo = list.find((v) => (v.name || '').includes('Google í•œêµ­'));
      const ko = list.find((v) => (v.lang || '').toLowerCase().startsWith('ko'));
      voiceRef.current = googleKo || ko || list[0] || null;
    };

    pickVoice(); // ì¦‰ì‹œ í•œ ë²ˆ
    window.speechSynthesis.onvoiceschanged = pickVoice; // ë¹„ë™ê¸° ë¡œë”© ëŒ€ë¹„
    return () => {
      window.speechSynthesis.onvoiceschanged = null;
    };
  }, []);

  // ğŸ”Š ì½ê¸° í•¨ìˆ˜
  function speakQuestion(text) {
    const synth = synthRef.current;
    if (!synth || !text) return;
    // ì´ì „ ì½ê¸° ì¤‘ì´ë©´ ì·¨ì†Œ
    if (synth.speaking || synth.paused) synth.cancel();

    const u = new SpeechSynthesisUtterance(text);
    if (voiceRef.current) u.voice = voiceRef.current;
    u.lang = voiceRef.current?.lang || 'ko-KR';
    u.rate = 1;
    u.pitch = 1;

    // (ì„ íƒ) ì½ê¸° ëë‚˜ë©´ ìë™ ë…¹ìŒ ì‹œì‘í•˜ê³  ì‹¶ë‹¤ë©´:
    // u.onend = () => { if (!isQuestionRecording) startQuestionAudio(); };

    utterRef.current = u;
    synth.speak(u);
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ê¶Œí•œ ë° ìŠ¤íŠ¸ë¦¼ ì¤€ë¹„
  const setupMedia = async () => {
    // ë¹„ë””ì˜¤ ì •ì˜
    const videoStream = await navigator.mediaDevices.getUserMedia({
      video: { width: 1280, height: 720 },
      audio: true,
    });

    // ì˜¤ë””ì˜¤ ì •ì˜
    const audioStream = await navigator.mediaDevices.getUserMedia({
      audio: true,
      video: false,
    });

    videoStreamRef.current = videoStream;
    audioStreamRef.current = audioStream;

    if (videoElRef.current) {
      videoElRef.current.srcObject = videoStream;
      await videoElRef.current.play().catch(() => {});
    }
  };

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ì„¸ì…˜ ì‹œì‘ / ì¢…ë£Œ
  const startSession = async () => {
    // falseì´ë‹ˆ return ì•„ë‹ˆë©´ ì§„í–‰
    if (isSessionStarted) return;
    await setupMedia();

    const videoRec = new RecordRTCPromisesHandler(videoStreamRef.current, {
      type: 'video',
      mimeType: 'video/mp4',
    });
    videoRecRef.current = videoRec;
    await videoRec.startRecording();

    setIsSessionStarted(true);
    setTimeLeft(MAX_SECONDS);

    // ì²« ì§ˆë¬¸ ìë™ ì½ê¸°
    // speakQuestion(QUESTIONS[0]);
    setcurrentQuestion(QUESTIONS[0]);
  };

  const stopSession = async () => {
    // ì§ˆë¬¸ ì˜¤ë””ì˜¤ ì •ë¦¬
    await stopQuestionAudio(true);

    // ë¹„ë””ì˜¤ ì €ì¥
    if (videoRecRef.current) {
      await videoRecRef.current.stopRecording();
      const blob = await videoRecRef.current.getBlob();
      const url = URL.createObjectURL(blob);
      setVideoUrl(url);
      videoRecRef.current.reset();
      videoRecRef.current.destroy();
      videoRecRef.current = null;
    }

    cleanupStreams();

    // TTS ì¤‘ì§€
    if (synthRef.current) synthRef.current.cancel();

    setIsSessionStarted(false);
  };

  const cleanupStreams = () => {
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current);
      timeoutRef.current = null;
    }
    if (videoStreamRef.current) {
      videoStreamRef.current.getTracks().forEach((t) => t.stop());
      videoStreamRef.current = null;
    }
    if (audioStreamRef.current) {
      audioStreamRef.current.getTracks().forEach((t) => t.stop());
      audioStreamRef.current = null;
    }
  };

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ì§ˆë¬¸ ì˜¤ë””ì˜¤ ì‹œì‘/ì •ì§€
  const startQuestionAudio = async () => {
    if (!audioStreamRef.current || isQuestionRecording) return;

    // íƒ€ì´ë¨¸ ì´ˆê¸°í™”
    if (timerRef.current) clearInterval(timerRef.current);
    if (timeoutRef.current) clearTimeout(timeoutRef.current);

    const audioRec = new RecordRTCPromisesHandler(audioStreamRef.current, {
      type: 'audio',
      recorderType: RecordRTC.StereoAudioRecorder,
      numberOfAudioChannels: 1,
      disableLogs: true,
    });
    audioRecRef.current = audioRec;
    await audioRec.startRecording();

    finishingRef.current = false; // ìƒˆë¡œìš´ ì§ˆë¬¸ ì‹œì‘ ì‹œ ê°€ë“œ ë¦¬ì…‹
    setIsQuestionRecording(true);
    setTimeLeft(MAX_SECONDS);

    // â± í‘œì‹œìš© 1ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´
    timerRef.current = setInterval(() => {
      setTimeLeft((prev) => {
        if (prev <= 1) {
          clearInterval(timerRef.current);
          timerRef.current = null;
          return 0;
        }
        return prev - 1;
      });
    }, 1000);

    //  ë‹¨ë°œ íƒ€ì„ì•„ì›ƒ: ì •í™•íˆ í•œ ë²ˆë§Œ finishAnswer í˜¸ì¶œ
    timeoutRef.current = setTimeout(() => {
      finishAnswer();
    }, MAX_SECONDS * 1000);
  };

  const stopQuestionAudio = async (silent = false) => {
    if (!audioRecRef.current) return;
    try {
      await audioRecRef.current.stopRecording();
      const blob = await audioRecRef.current.getBlob();
      const url = URL.createObjectURL(blob);

      setAudioUrls((prev) => {
        const next = [...prev];
        next[currentIdx] = url; // í˜„ì¬ ì§ˆë¬¸ ì¸ë±ìŠ¤ì— ìŒì„± URL ì €ì¥
        return next;
      });

      audioRecRef.current.reset();
      audioRecRef.current.destroy();
      audioRecRef.current = null;
    } catch (e) {
      if (!silent) console.error(e);
    } finally {
      setIsQuestionRecording(false);
    }
  };

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ë„¤ë¹„ê²Œì´ì…˜ & ìë™ ì½ê¸° íŠ¸ë¦¬ê±°
  const goNextQuestion = () => {
    if (currentIdx < QUESTIONS.length - 1) {
      setCurrentIdx((idx) => idx + 1);
      setTimeLeft(MAX_SECONDS);
    } else {
      stopSession();
    }
  };

  //  ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë°”ë€Œë©´ ìë™ ì½ê¸°
  useEffect(() => {
    if (!isSessionStarted) return;
    // ë…¹ìŒ ì¤‘ì—ëŠ” ì½ì§€ ì•Šìœ¼ë ¤ë©´ ì•„ë˜ ê°€ë“œ ì¶”ê°€
    // if (isQuestionRecording) return;

    const q = QUESTIONS[currentIdx] || '';
    // speakQuestion(q);
    setcurrentQuestion(QUESTIONS[currentIdx]);
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [currentIdx, isSessionStarted]);

  const startAnswer = async () => {
    if (!isSessionStarted || isQuestionRecording) return;
    await startQuestionAudio();
  };

  const finishAnswer = async () => {
    if (finishingRef.current) return; // ì¤‘ë³µ ë°©ì§€
    finishingRef.current = true;

    // íƒ€ì´ë¨¸ ì •ë¦¬ (í‘œì‹œ/íƒ€ì„ì•„ì›ƒ ëª¨ë‘)
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current);
      timeoutRef.current = null;
    }

    await stopQuestionAudio();
    goNextQuestion();

    // ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ë‹¤ì‹œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê°€ë“œ í•´ì œ
    finishingRef.current = false;
  };

  // ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      cleanupStreams();
      if (synthRef.current) synthRef.current.cancel(); //  TTS ì¤‘ì§€
      audioUrls.forEach((u) => u && URL.revokeObjectURL(u));
      if (videoUrl) URL.revokeObjectURL(videoUrl);
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // UI
  return (
    <div style={{ padding: 24, fontFamily: 'Inter, system-ui, sans-serif' }}>
      <TextToSpeech voice={voiceId} currentQuestion={currentQuestion} />
      {/* ì»¨íŠ¸ë¡¤ */}
      <div style={{ display: 'flex', gap: 12, marginBottom: 12, alignItems: 'center' }}>
        <button style={btnStyle} onClick={isSessionStarted ? stopSession : startSession}>
          {isSessionStarted ? 'ì„¸ì…˜ ì¢…ë£Œ' : 'ì„¸ì…˜ ì‹œì‘'}
        </button>
        <button
          style={btnStyle}
          onClick={startAnswer}
          disabled={!isSessionStarted || isQuestionRecording}
        >
          ë‹µë³€í•˜ê¸° (ë…¹ìŒ ì‹œì‘)
        </button>
        <button
          style={btnStyle}
          onClick={finishAnswer}
          disabled={!isSessionStarted || !isQuestionRecording}
        >
          ë‹µë³€ ì™„ë£Œ (ì €ì¥ í›„ ë‹¤ìŒ)
        </button>
        <div style={pillStyle}>
          <strong>{formatTime(timeLeft)}</strong>
        </div>
        <span style={{ marginLeft: 8 }}>
          {currentIdx + 1}/{QUESTIONS.length}
        </span>
        {isQuestionRecording && <span style={{ fontSize: 12 }}>ë…¹ìŒ ì¤‘...</span>}
      </div>

      {/* í˜„ì¬ ì§ˆë¬¸ í‘œì‹œ */}
      <div style={{ marginBottom: 8 }}>
        <span
          style={{
            fontSize: 12,
            color: '#64748B',
            marginRight: 8,
            border: '1px solid #D4CAFE',
            borderRadius: 8,
            padding: '2px 6px',
          }}
        >
          Q{currentIdx + 1}
        </span>
        <span>{QUESTIONS[currentIdx]}</span>
      </div>

      {/* ì˜ìƒ ë³´ì´ê¸° */}
      <div
        style={{
          border: '1px solid #cfcfcf',
          borderRadius: 14,
          padding: 8,
          width: 520,
          height: 320,
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          marginBottom: 16,
        }}
      >
        <video
          ref={videoElRef}
          autoPlay
          playsInline
          muted
          style={{ width: '100%', height: '100%', borderRadius: 10, objectFit: 'cover' }}
        />
      </div>

      {/* ë…¹ìŒ ì§„í–‰/ì €ì¥ (ì§ˆë¬¸ë³„ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ) */}
      <div>
        <h4 style={{ margin: '12px 0 8px' }}>ë…¹ìŒ íŒŒì¼(ì§ˆë¬¸ë³„)</h4>
        <ol style={{ paddingLeft: 18, lineHeight: 1.9 }}>
          {QUESTIONS.map((_, i) => (
            <li key={i}>
              Q{i + 1}.{' '}
              {audioUrls[i] ? (
                <a href={audioUrls[i]} download={`q${i + 1}.webm`}>
                  ë‹¤ìš´ë¡œë“œ
                </a>
              ) : (
                <span style={{ color: '#999' }}>ì•„ì§ ìƒì„±ë˜ì§€ ì•ŠìŒ</span>
              )}
            </li>
          ))}
        </ol>
      </div>

      {/* ì˜ìƒ ì €ì¥ í•­ëª© (ì„¸ì…˜ ë¹„ë””ì˜¤) */}
      <div style={{ marginTop: 16 }}>
        <h4 style={{ margin: '12px 0 8px' }}>ì„¸ì…˜ ë¹„ë””ì˜¤</h4>
        {videoUrl ? (
          <div style={{ display: 'flex', gap: 12, alignItems: 'center' }}>
            <video src={videoUrl} controls style={{ width: 320, borderRadius: 10 }} />
            <a href={videoUrl} download='session.webm'>
              ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
            </a>
          </div>
        ) : (
          <span style={{ color: '#999' }}>ì„¸ì…˜ ë¹„ë””ì˜¤ ì—†ìŒ</span>
        )}
      </div>
    </div>
  );
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ìŠ¤íƒ€ì¼ ìœ í‹¸
const btnStyle = {
  borderRadius: 10,
  cursor: 'pointer',
};

const pillStyle = {
  background: '#000',
  color: '#fff',
  padding: '6px 14px',
  fontWeight: 700,
  minWidth: 120,
  textAlign: 'center',
};

function formatTime(s) {
  const mm = String(Math.floor(s / 60)).padStart(2, '0');
  const ss = String(s % 60).padStart(2, '0');
  return `${mm}:${ss}`;
}
